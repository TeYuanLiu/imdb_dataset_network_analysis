{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, pickle\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as mcs\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from tqdm import tqdm as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Director rating dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"movie_rating.txt\"\n",
    "\n",
    "movie_rating_dict = {}\n",
    "line_count = 0\n",
    "\n",
    "with open(fname, encoding=\"ISO-8859-1\") as fin:\n",
    "    for line in fin:\n",
    "        line_count += 1\n",
    "        obj_list = re.split(r\"\\t+\", line) ############# change to \\t        \n",
    "\n",
    "        obj = obj_list[0]\n",
    "\n",
    "        p1 = re.search(r\"\\((\\d{4}|\\?{4})[^()]*\\)(.+)\", obj)\n",
    "        if p1:\n",
    "            obj = obj.replace(p1.group(2),\"\")\n",
    "            movie_rating_dict[obj]=obj_list[1]\n",
    "        else:\n",
    "            p2 = re.search(r\"\\((\\d{4}|\\?{4})[^()]*\\)\", obj)\n",
    "            if not p2:\n",
    "                obj = obj + \" (????)\"\n",
    "            movie_rating_dict[obj]=obj_list[1]\n",
    "\n",
    "pickle.dump(movie_rating_dict, open(\"movie_rating_dict.pkl\", \"wb\" ))\n",
    "            \n",
    "with open(\"movie_rating_clean.txt\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for k, v in movie_rating_dict.items():\n",
    "        outfile.write(\"%s,%s\\n\" %(k, v)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"director_movies.txt\"\n",
    "\n",
    "director_movie_dict = {}\n",
    "movie_director_dict = {}\n",
    "line_count = 0\n",
    "\n",
    "num = 0\n",
    "with open(fname, encoding=\"ISO-8859-1\") as fin:\n",
    "    for line in fin:\n",
    "        line_count += 1\n",
    "        obj_list = re.split(r\"\\t+\", line) ############# change to \\t        \n",
    "        if len(obj_list) < 2: ############### change to 11 later\n",
    "            continue\n",
    "        strip_list = []\n",
    "        for obj in obj_list:\n",
    "            strip_list.append(obj.strip(\"\\n\").strip())\n",
    "        strip_list = list(filter(None, strip_list))\n",
    "        obj_count = 0\n",
    "        director_name = strip_list[0]\n",
    "        director_name = director_name.replace(\" \", \"\")\n",
    "        if director_name not in director_movie_dict:\n",
    "            new_movie_list = []\n",
    "            director_movie_dict[director_name] = new_movie_list\n",
    " #       new_movie_list = []\n",
    " #       director_movie_dict[director_name] = new_movie_list\n",
    "\n",
    "        for obj in strip_list:\n",
    "            obj_count += 1\n",
    "\n",
    "            if obj_count >= 2:\n",
    "                p1 = re.search(r\"\\((\\d{4}|\\?{4})[^()]*\\)(.+)\", obj)\n",
    "                if p1:\n",
    "                        obj = obj.replace(p1.group(2),\"\")\n",
    "                        ## movie 2 director dict update\n",
    "                        if movie_director_dict.get(obj) == None:\n",
    "                            new_director_list = []\n",
    "                            new_director_list.append(director_name)\n",
    "                            movie_director_dict[obj] = new_director_list\n",
    "                        else:\n",
    "                            movie_director_dict[obj].append(director_name)                        \n",
    "                        ## director 2 movie dict update\n",
    "                        director_movie_dict[director_name].append(obj)\n",
    "                else:\n",
    "                        p2 = re.search(r\"\\((\\d{4}|\\?{4})[^()]*\\)\", obj)\n",
    "                        if not p2:\n",
    "                            obj = obj + \" (????)\"\n",
    "                        ## movie 2 director dict update\n",
    "                        if movie_director_dict.get(obj) == None:\n",
    "                            new_director_list = []\n",
    "                            new_director_list.append(director_name)\n",
    "                            movie_director_dict[obj] = new_director_list\n",
    "                        else:\n",
    "                            movie_director_dict[obj].append(director_name) \n",
    "                        ## director 2 movie dict update                        \n",
    "                        director_movie_dict[director_name].append(obj)\n",
    "                \n",
    "pickle.dump(director_movie_dict, open(\"director_movie_dict.pkl\", \"wb\" ))\n",
    "pickle.dump(movie_director_dict, open(\"movie_director_dict.pkl\", \"wb\" ))\n",
    "\n",
    "with open(\"director_movie_clean.txt\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for k, v in director_movie_dict.items():\n",
    "        for d in v:\n",
    "            outfile.write(\"%s,%s\\n\" %(k, d)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_rating_dict = {}\n",
    "for key, value in director_movie_dict.items():\n",
    "    sum_ratings = 0\n",
    "    count = 0\n",
    "    for mv in value:\n",
    "        if mv in movie_rating_dict:\n",
    "            sum_ratings += float(movie_rating_dict[mv])\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        director_rating_dict[key] = sum_ratings/count\n",
    "\n",
    "pickle.dump(director_rating_dict, open(\"director_rating_dict.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113611"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(director_rating_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igraph import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergetxt(fnames):\n",
    "    with open(\"merged.txt\", \"w\", encoding=\"ISO-8859-1\") as outfile:\n",
    "        for fname in fnames:\n",
    "            with open(fname, encoding=\"ISO-8859-1\") as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "file_names = [\"actor_movies.txt\", \"actress_movies.txt\"]\n",
    "mergetxt(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  113129  actors/actresses and  468244  unique movies...\n",
      "There are  113050  nodes in the cast network...\n"
     ]
    }
   ],
   "source": [
    "cast_movie_dict = {}\n",
    "movie_cast_dict = {}\n",
    "fname = \"merged.txt\"\n",
    "line_count = 0\n",
    "cast_count = 0\n",
    "with open(fname, encoding=\"ISO-8859-1\") as fin:\n",
    "    for line in fin:\n",
    "        line_count += 1\n",
    "        obj_list = re.split(r\"\\t+\", line) ############# change to \\t\n",
    "        if len(obj_list) < 11: ############### change to 11 later\n",
    "            continue\n",
    "        cast_count += 1\n",
    "        strip_list = []\n",
    "        for obj in obj_list:\n",
    "            strip_list.append(obj.strip(\"\\n\").strip())\n",
    "        strip_list = list(filter(None, strip_list))\n",
    "        obj_count = 0\n",
    "        cast_name = strip_list[0]\n",
    "        cast_name = cast_name.replace(\" \", \"\")\n",
    "        new_movie_list = []\n",
    "        cast_movie_dict[cast_name] = new_movie_list\n",
    "        for obj in strip_list:\n",
    "            obj_count += 1\n",
    "            if obj_count >= 2:\n",
    "                p1 = re.search(r\"\\((\\d{4}|\\?{4})[^()]*\\)(.+)\", obj)\n",
    "                if p1:\n",
    "                    obj = obj.replace(p1.group(2),\"\")\n",
    "                    ## movie 2 cast dict update\n",
    "                    if obj in movie_cast_dict:\n",
    "                        movie_cast_dict[obj].append(cast_name)\n",
    "                    else:\n",
    "                        new_cast_list = []\n",
    "                        new_cast_list.append(cast_name)\n",
    "                        movie_cast_dict[obj] = new_cast_list\n",
    "                    ## cast 2 movie dict update\n",
    "                    cast_movie_dict[cast_name].append(obj)\n",
    "                else:\n",
    "                    p2 = re.search(r\"\\((\\d{4}|\\?{4})[^()]*\\)\", obj)\n",
    "                    if not p2:\n",
    "                        obj = obj + \" (????)\"\n",
    "                    # movie 2 cast dict update\n",
    "                    if obj in movie_cast_dict:\n",
    "                        movie_cast_dict[obj].append(cast_name)\n",
    "                    else:\n",
    "                        new_cast_list = []\n",
    "                        new_cast_list.append(cast_name)\n",
    "                        movie_cast_dict[obj] = new_cast_list\n",
    "                    ## cast 2 movie dict update\n",
    "                    cast_movie_dict[cast_name].append(obj)\n",
    "print(\"There are \",len(cast_movie_dict),\" actors/actresses and \",len(movie_cast_dict),\" unique movies...\")\n",
    "\n",
    "pickle.dump(cast_movie_dict, open(\"cast_movie_dict.pkl\", \"wb\" ))\n",
    "pickle.dump(movie_cast_dict, open(\"movie_cast_dict.pkl\", \"wb\" ))\n",
    "\n",
    "## create edge list for actor/actress network\n",
    "dic = {}\n",
    "edgelist_dict = {}\n",
    "for c1, ml in cast_movie_dict.items():\n",
    "    for m in ml:\n",
    "        for c2 in movie_cast_dict[m]:\n",
    "            if c1 != c2:\n",
    "                dic[c1] = 1\n",
    "                dic[c2] = 1\n",
    "                key = c1 + \"\\n\" + c2\n",
    "                if edgelist_dict.get(key) == None:\n",
    "                    edgelist_dict[key] = 1.0/len(ml)\n",
    "                else:\n",
    "                    edgelist_dict[key] += 1.0/len(ml)\n",
    "print(\"There are \",len(dic),\" nodes in the cast network...\")\n",
    "\n",
    "with open(\"cast_network_edgelist.txt\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for k, v in edgelist_dict.items():\n",
    "        c1, c2 = k.split(\"\\n\")\n",
    "        line = c1 + '\\t' + c2 + '\\t' + str(v) + '\\n'\n",
    "#        line = \",\".join([c1.replace(\",\", \"\"), c2.replace(\",\", \"\"), str(v)]) + \"\\n\"\n",
    "        outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph.Read_Ncol('cast_network_edgelist.txt', directed=True)\n",
    "page_rank = g.pagerank(vertices=None, directed=True)\n",
    "actor_pagerank_dict = {}\n",
    "for idx, v in enumerate(g.vs):\n",
    "    actor_pagerank_dict[v[\"name\"]] = page_rank[idx]\n",
    "    \n",
    "pickle.dump(actor_pagerank_dict, open(\"actor_pagerank_dict.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_pagerank_dict = pickle.load(open(\"actor_pagerank_dict.pkl\", \"rb\" ))\n",
    "director_rating_dict = pickle.load(open(\"director_rating_dict.pkl\", \"rb\" ))\n",
    "cast_movie_dict = pickle.load(open(\"cast_movie_dict.pkl\", \"rb\" ))\n",
    "movie_cast_dict = pickle.load(open(\"movie_cast_dict.pkl\", \"rb\" ))\n",
    "director_movie_dict = pickle.load(open(\"director_movie_dict.pkl\", \"rb\" ))\n",
    "movie_director_dict = pickle.load(open(\"movie_director_dict.pkl\", \"rb\" ))\n",
    "movie_rating_dict = pickle.load(open(\"movie_rating_dict.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_10cast_dict = {}\n",
    "\n",
    "for mv, cast in movie_cast_dict.items():\n",
    "    if len(cast)>9:\n",
    "        movie_10cast_dict[mv] = cast\n",
    "\n",
    "movie_with_CR = set(movie_10cast_dict.keys()).intersection(movie_rating_dict.keys())\n",
    "avail_movies = set(movie_with_CR).intersection(movie_director_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83537"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avail_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83537/83537 [00:02<00:00, 28739.38it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_feature(movie):\n",
    "    features = [0] * 6\n",
    "    actors = movie_10cast_dict[movie]\n",
    "    page_ranks = []\n",
    "    for actor in actors:\n",
    "        page_ranks.append(actor_pagerank_dict[actor])\n",
    "    sorted_page_ranks = sorted(page_ranks, reverse=True)\n",
    "    features[:5] = sorted_page_ranks[:5]\n",
    "    \n",
    "    directors = movie_director_dict[movie]\n",
    "    director_ratings = 0\n",
    "    count = 0\n",
    "    for director in directors:\n",
    "        if director in director_rating_dict:\n",
    "            director_ratings += float(director_rating_dict[director])\n",
    "            count += 1\n",
    "    features[5] = director_ratings/count\n",
    "    return np.array(features)\n",
    "\n",
    "feature_vector = np.vstack(map(build_feature, timer(avail_movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83537/83537 [00:00<00:00, 377217.06it/s]\n"
     ]
    }
   ],
   "source": [
    "actual_rating = []\n",
    "for movie in timer(avail_movies):\n",
    "    actual_rating.append(float(movie_rating_dict[movie]))\n",
    "rating_vector = np.array(actual_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(feature_vector, rating_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movies = [\n",
    "    \"Batman v Superman: Dawn of Justice (2016)\",\n",
    "    \"Mission: Impossible - Rogue Nation (2015)\",\n",
    "    \"Minions (2015)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batman v Superman: Dawn of Justice (2016): 7.26\n",
      "Mission: Impossible - Rogue Nation (2015): 6.84\n",
      "Minions (2015): 7.17\n"
     ]
    }
   ],
   "source": [
    "for mv in test_movies:\n",
    "    print (\"%s: %.2f\" %(mv,model.predict([build_feature(mv)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6881090242779832"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcs.mean_squared_error(rating_vector, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
